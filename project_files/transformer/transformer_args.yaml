model:
  # an example below
  #
  #  self.model = GRUDecoder(
  #    neural_dim = self.args['model']['n_input_features'],
  #    n_units = self.args['model']['n_units'],
  #    n_days = len(self.args['dataset']['sessions']),
  #    n_classes  = self.args['dataset']['n_classes'],
  #    rnn_dropout = self.args['model']['rnn_dropout'],
  #    input_dropout = self.args['model']['input_network']['input_layer_dropout'],
  #    n_layers = self.args['model']['n_layers'],
  #    patch_size = self.args['model']['patch_size'],
  #    patch_stride = self.args['model']['patch_stride'],
  #  )
  #
  # so they put
  #  n_input_features: 512 # number of input features in the neural data. (2 features per electrode, 256 electrodes)
  #  n_units: 768 # number of units per GRU layer
  #  rnn_dropout: 0.4 # dropout rate for the GRU layers
  #  rnn_trainable: true # whether the GRU layers are trainable
  #  n_layers: 5 # number of GRU layers
  #  patch_size: 14 # size of the input patches (14 time steps)
  #  patch_stride: 4 # stride for the input patches (4 time steps)
  #
  #  input_network:
  #    n_input_layers: 1 # number of input layers per network (one network for each day)
  #    input_layer_sizes:
  #    - 512 # size of the input layer (number of input features)
  #    input_trainable: true # whether the input layer is trainable
  #    input_layer_dropout: 0.2 # dropout rate for the input layer

# TODO: add more args as needed

dataset:
  data_transforms:
    white_noise_std: 1.0 # standard deviation of the white noise added to the data
    constant_offset_std: 0.2 # standard deviation of the constant offset added to the data
    random_walk_std: 0.0 # standard deviation of the random walk added to the data
    random_walk_axis: -1 # axis along which the random walk is applied
    static_gain_std: 0.0 # standard deviation of the static gain applied to the data
    random_cut: 3 # number of time steps to randomly cut from the beginning of each batch of trials
    smooth_kernel_size: 100 # size of the smoothing kernel applied to the data
    smooth_data: true # whether to smooth the data
    smooth_kernel_std: 2 # standard deviation of the smoothing kernel applied to the data

  neural_dim: 512 # dimensionality of the neural data
  batch_size: 64 # batch size for training
  n_classes: 41 # number of classes (phonemes) in the dataset
  max_seq_elements: 500 # maximum number of sequence elements (phonemes) for any trial
  days_per_batch: 4 # number of randomly-selected days to include in each batch
  seed: 1 # random seed for reproducibility
  num_dataloader_workers: 4 # number of workers for the data loader
  loader_shuffle: false # whether to shuffle the data loader
  must_include_days: null # specific days to include in the dataset
  test_percentage: 0.1 # percentage of data to use for testing
  feature_subset: null # specific features to include in the dataset

  dataset_dir: ../../data/hdf5_data_final # directory containing the dataset, needs the double ../ this time
  bad_trials_dict: null # dictionary of bad trials to exclude from the dataset
  sessions: # list of sessions to include in the dataset
  - t15.2023.08.11
  - t15.2023.08.13
  - t15.2023.08.18
  - t15.2023.08.20
  - t15.2023.08.25
  - t15.2023.08.27
  - t15.2023.09.01
  - t15.2023.09.03
  - t15.2023.09.24
  - t15.2023.09.29
  - t15.2023.10.01
  - t15.2023.10.06
  - t15.2023.10.08
  - t15.2023.10.13
  - t15.2023.10.15
  - t15.2023.10.20
  - t15.2023.10.22
  - t15.2023.11.03
  - t15.2023.11.04
  - t15.2023.11.17
  - t15.2023.11.19
  - t15.2023.11.26
  - t15.2023.12.03
  - t15.2023.12.08
  - t15.2023.12.10
  - t15.2023.12.17
  - t15.2023.12.29
  - t15.2024.02.25
  - t15.2024.03.03
  - t15.2024.03.08
  - t15.2024.03.15
  - t15.2024.03.17
  - t15.2024.04.25
  - t15.2024.04.28
  - t15.2024.05.10
  - t15.2024.06.14
  - t15.2024.07.19
  - t15.2024.07.21
  - t15.2024.07.28
  - t15.2025.01.10
  - t15.2025.01.12
  - t15.2025.03.14
  - t15.2025.03.16
  - t15.2025.03.30
  - t15.2025.04.13
  dataset_probability_val: # probability of including a trial in the validation set (0 or 1)
  - 0 # no val or test data from this day
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 0 # no val or test data from this day
  - 1
  - 1
  - 1
  - 0 # no val or test data from this day
  - 0 # no val or test data from this day
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1